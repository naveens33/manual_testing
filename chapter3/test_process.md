# Fundamental Test Process - Key Concepts and Notes

## 1. Requirements Analysis/Design:
### 1.1. Understand the requirements:
- Analyze and comprehend the software requirements to determine the testing scope and objectives.
- Identify any ambiguities or inconsistencies in the requirements that may impact the testing process.

### 1.2. Prepare Traceability Matrix:
- Create a traceability matrix to establish the relationship between requirements, test cases, and other testing artifacts.
- Helps ensure that all requirements are adequately tested and provides visibility into test coverage.

## 2. Test Planning:
### 2.1. Object:
- Define the purpose and goals of the testing effort.
- Determine the key objectives and expectations from the testing process.

### 2.2. Scope of Testing:
- Identify the functionalities and features to be tested and the ones that will be excluded.
- Set boundaries for the testing activities.

### 2.3. Schedule:
- Create a timeline for the testing activities, including test preparation, execution, and reporting.
- Consider dependencies, project milestones, and resource availability.

### 2.4. Approach:
- Define the overall testing strategy and approach, such as manual testing, automation, or a combination of both.
- Consider factors like risk, complexity, and available resources.

### 2.5. Roles & Responsibilities:
- Assign specific roles and responsibilities to individuals involved in the testing process, such as test leads, testers, and stakeholders.
- Clarify the expectations and duties of each role.

### 2.6. Assumptions:
- Identify any assumptions made during the test planning phase that may affect the testing process.
- Documenting assumptions helps in understanding the context and constraints of the testing effort.

### 2.7. Risks & Mitigations:
- Identify potential risks that may impact the success of the testing activities.
- Define strategies to mitigate or minimize the impact of those risks.

### 2.8. Entry & Exit Criteria:
- Establish criteria that define when to start and conclude testing activities.
- Entry criteria include prerequisites that must be met before testing can begin, while exit criteria determine when testing can be considered complete.

### 2.9. Test Automation:
- Determine if test automation will be used and identify the tools, frameworks, and scripts required.
- Evaluate the benefits and feasibility of automation based on the project context.

### 2.10. Deliverables:
- Specify the expected deliverables from the testing process, such as test plans, test cases, test reports, and defect logs.
- Define the format and content requirements for each deliverable.

## 3. Test Cases Design:
### 3.1. Write Test Cases:
- Create detailed test cases based on the requirements and expected behavior of the software.
- Include input values, expected outputs, and steps to execute the test.

### 3.2. Review Test Cases:
- Conduct a peer review or walkthrough of the test cases to identify any gaps, errors, or improvements.
- Ensure that the test cases are clear, comprehensive, and aligned with the requirements.

### 3.3. Test Cases Template:
- Define a standardized format or template for documenting test cases.
- This helps ensure consistency and ease of understanding across the testing team.

### 3.4. Types of Test Cases:
- Understand and utilize various types of test cases, such as functional, performance, usability, security, and integration, based on the testing objectives.

### 3.5. Difference between Test Scenarios and Test Cases:
- Test scenarios represent high-level test conditions or situations, while test cases provide specific steps and inputs for executing the test.
- Test scenarios guide the creation of test cases by outlining the key scenarios to be tested.

## 4. Test Environment Setup:
### 4.1. Understand the SRS:
- Familiarize yourself with the Software Requirements Specification (SRS) document to understand the software architecture and system behavior.

### 4.2. Hardware and Software Requirements:
- Identify and set up the necessary hardware and software components for the testing environment.
- This includes the required operating systems, databases, browsers, and other dependencies.

### 4.3. Test Data:
- Prepare or acquire suitable test data that covers different scenarios and conditions.
- Ensure that the test data is representative of real-world usage.

## 5. Test Execution:
### 5.1. Execute Test Cases:
- Run the prepared test cases and record the actual results.
- Compare the observed outcomes with the expected results.

### 5.2. Defect Tracking and Reporting:
- Log and track any identified defects using a defect tracking system or tool.
- Record relevant information, such as steps to reproduce, severity, and priority.

### 5.3. Types of Bugs:
- Understand different types of bugs, including functional defects, usability issues, performance bottlenecks, security vulnerabilities, etc.

### 5.4. Identifying the Bugs:
- Apply various techniques, such as boundary value analysis, equivalence partitioning, and exploratory testing, to identify defects efficiently.

### 5.5. Bug/Defect Life Cycle:
- Understand the typical stages that a defect goes through, from discovery to resolution.
- This includes states like New, Assigned, Open, Fixed, Retested, Closed, etc.

### 5.6. Reporting the Bugs:
- Communicate the identified defects to the development team or relevant stakeholders.
- Provide clear and concise bug reports with all the necessary details for effective communication and resolution.

### 5.7. Severity and Priority:
- Assign severity levels to defects based on their impact on the software's functionality, performance, or usability.
- Prioritize defects based on their criticality and impact on the overall testing goals.

## 6. Test Closure:
### 6.1. Criteria for Test Closure:
- Define the conditions that need to be met to conclude the testing phase.
- This may include achieving a certain level of test coverage, resolving critical defects, and meeting predefined exit criteria.

### 6.2. Test Summary Report:
- Prepare a test summary report that documents the testing activities, results, metrics, and any lessons learned.
- Summarize the overall quality of the software and provide recommendations for future improvements.
